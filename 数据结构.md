# 字节对齐
现代计算机中内存空间都是按照字节划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但实际情况是在访问特定变量的时候经常在特定的内存访问，这就需要各类型数据按照一定的规则在空间上排列，而不是顺序地一个接一个的排放。为了提高效率，计算机从内存中取数据是按照一个固定的长度，以32位机器为例，它每次取 32 个 bit，也就是 4 个字节，对于一个 int 型数据，只需要取一次就可以了。
``` cpp
struct Family {
  char member1;
  short member2;
  int member3;
};
// sizeof(Family) = 8

/* ---------------------------- */
struct Family {
  char member1;
  int member2;
  short member3;
};
// sizeof(Family) = 12
```
![[Pasted image 20221219005559.png|350x200]]    ![[Pasted image 20221219013224.png|350x200]]

# 字节对齐准则
- char 自身对齐值为 1 字节，short 为 2 字节，int/float 为 4 字节，double 为 8 字节
- 结构体或类的自身对齐值：其成员中自身对齐值最大的那个值
- 指定对齐值：`#pragma pack (value)` 时的指定对齐值 value
- 有效对齐值 = min { 自身对齐值，当前指定的 pack 值 }

有效对齐值 N 是最终用来决定数据存放地址方式的值，即该数据的存放起始地址 % N = 0 。结构体的成员变量要对齐存放，结构体本身也要根据自身的有效对齐值圆整。
``` cpp
#pragma pack(push, 8)
struct Test {
  char i[10];
};  // 数组按照单个元素进行内存对齐，所以对齐值为1，sizeof(Test) = 10

struct Test1 {
  short s1;
  Test i1;
};  // 自身对齐值为2，sizeof(Test1) = 12

struct Test2 {
  int i1;
  char* p;
  char c1;
};  // 自身对齐值为8，sizeof(Test2) = 24
#pragma pack(pop)
```

[Data Structure Alignment - GeeksforGeeks](https://www.geeksforgeeks.org/data-structure-alignment-how-data-is-arranged-and-accessed-in-computer-memory/)

# 什么是 allocator
每一个 STL 的容器类都有一个 Allocator 来进行空间的配置
``` cpp
template <class T, class Allocator = allocator<T> >
class vector {
  // ...
}
```
Allocator 不仅帮助我们完成内存的分配和释放，也帮助我们完成对象的构造和析构。为了解决内存碎片的问题，SGI 设计了双层配置器：
- 当配置区块超过 128 字节时，调用第一级配置器
- 当配置区块小于 128 字节时，调用第二级配置器（内存池）

第一级配置器是基于 malloc 实现的配置器，一般而言是线程安全的，并且对于空间的运用比较高效。如果内存不足，会循环调用内存不足的处理线程（设计内存不足的处理线程是用户的责任）。
第二级配置器维护 16 个 free-lists ，各自管理大小分别为8，16，24，32，...，120，128 字节的小额区块。会将任何小额区块的内存需求上调至 8 的倍数。
![[Pasted image 20221219023559.png|center|400]]

自由链表使用 union 让两个指针共用一块内存地址：
``` cpp
union obj {
  union obj* free_list_link;
  char client_data[1]
};
```

# STL容器的底层实现
vector - 数组，支持快速随机访问
list - 双向链表，支持快速删除
deque - 中央控制器和多个缓冲区
stack/queue - list 或者 deque
set/map - 红黑树
unordered_map/unordered_set - 哈希表
priority_queue - vector

# vector的底层实现
vector 维护了一个连续的线性空间，随着元素的加入，它的内部机制会自行扩充空间以容纳新元素。以原大小的两倍另外配置一块较大的空间，然后将原内容拷贝过来。因此，对 vector 的任何操作，一旦引起空间的重新配置，指向原 vector 的所有迭代器都失效了。

# 为什么vector扩充2倍
因为当我们加入 n 个元素时，假设扩充因子是 k，那么我们总共需要扩充 $log_k⁡n$ 次，每次移动 $k^i$ 个元素。利用均摊分析法，插入元素的时间复杂度是：
$$
O(\frac{1}{n}\sum_{i=0}^{log_kn}k^i)=O(\frac{nk-1}{n*(k-1)})=O(1+\frac{1}{k-1})
$$
	所以，当 k > 1 的时候都是常数的时间复杂度。k 的值越大复杂度越低。但是我们需要兼顾空间和时间，所以 2 是一个比较好的选择。但是 2 的缺点是每次分配的时候所需要的空间都比前面释放的空间总和要大，不能利用原有的空间。如果按照 1.5 来分配，1，1.5，3，4.5，当分配 4.5 时，前面已分配 5.5，可以直接利用，把旧数据 move 过去。

# push_back和emplace_back
底层实现的机制不同，push_back 的参数必须是一个确定的类型；emplace_back 采用的是可变模版参数，可以接受多个参数。push_back 向容器尾部添加元素时，首先会创建这个元素，然后再将这个元素拷贝或者移动到容器中。emplace_back 直接在容器内构造对象，不用拷贝一个复制品再使用。

[C++姿势点: push_back和emplace_back - 知乎](https://zhuanlan.zhihu.com/p/183861524)
[C++ Diary #1 | emplace_back vs. push_back | Yasen Hu](https://yasenh.github.io/post/cpp-diary-1-emplace_back/)

# Reserve和Resize的区别
reserve 是预分配存储区的大小，即 capacity 的值；resize 重新分配大小，并且创建对象。

# 释放vector内存空间
clear 会清空 vector 中的数据，但是不会释放内存 (capacity 容量占用的空间) 。
通过 `vector<T>().swap(x);` 可以清空 vector 占用的内存。
通过 `vector<T>(x).swap(x);` 可以去除 vector 多余的容量。

# 删除vector中的元素
vector 的 remove 操作并不会直接删除对应的元素，而是将等于 target 的元素交换到末尾，所以如果想要删除所有等于 target 的值，可以将 remove 与 erase 操作合并：
``` cpp
v.erase(std::remove(v.begin(), v.end(), target), v.end());
```
在 for 循环中想要删除一个容器中的元素需要特别小心，正确的做法应该是：
``` cpp
for (auto it = v.begin(), it != v.end(); ) {
  if (it == 3)
    it = v.erase(iter);
  else
    it++;
}
```

# vector的拷贝方式
You are making a deep copy any time you copy a vector. But if your vector is a vector of pointers you are getting the copy of pointers, not the values are pointed to. 

For example:
``` cpp
std::vector<Foo> f;
std::vector<Foo> cp = f;  // deep copy. All Foo copied

std::vector<Foo*> f;
std::vector<Foo*> cp = f;  // All pointers to Foo are copied, but not Foo themselves
```

# map和unordered_map的区别
底层实现：map 是红黑树，unordered_map 是哈希表。
内存占用：unordered_map 需要一个很大的哈希表，需要额外的空间。
查询时间：红黑树需要 O(logn) ，哈希表是 O(1)，但是红黑树是有序的。

# map是线程安全的么
不是线程安全的，多线程读没有问题，如果写会出现竞争。可以使用读写锁来保证安全，但是要注意一个线程同时获得了读锁和写锁

# map删除元素迭代器失效
map 是关联容器，以红黑树或者平衡二叉树组织数据，虽然删除了一个元素，整棵树也会调整，以符合红黑树或者二叉树的规范，但是单个节点在内存中的地址没有变化，变化的是各节点之间的指向关系。

# map删除迭代器的写法
``` cpp
map<int, string>::iterator tmpIter = iter;
iter++;
dataMap.erase(tmpIter);

// 简单写法
// 这句话分三步走
//   1) 先把iter传值到erase里面;
//   2) 然后iter自增;
//   3) 然后执行erase
// 所以iter在失效前已经自增了
dataMap.erase(iter++);
```

# 红黑树
红黑树的数据结构如下：
``` cpp
enum Color { RED = 0, BLACK };
struct RBTreeNode {
  int val;
  Color color;
  RBTreeNode *left, *right;
};
```
红黑树是一种自平衡的二叉查找树，除了符合 BST 的特性之外，它还有如下特性：
- 节点是红色或黑色
- 根节点是黑色
- 每个叶子节点都是黑色的空节点 (NULL)
- 每个红色节点的两个子节点都是黑色 (不能有两个连续的红节点)
- 从任意节点到每个叶子的路径都包含相同数目的黑色节点
## 为什么根节点是黑色的
如果根节点是红色的，当我们插入新的节点，由于性质5，又要把根节点变为黑色。
## 为什么不能有两个连续的红节点
保证最长路径不超过最短路径的两倍。最短路径一定是全黑的，最长路径一定是黑红交替的，由于两条路径黑色节点的数量要相等，所以最长路径最多包含 n 个红节点。
## 红黑树有什么优点
BST树最坏情况下，查找效果可能是 O(n) 的，红黑树确保了最长路径不超过最短路径的两倍，所以它的查找效果始终是 O(logn) 的，保证了查询效果的稳定。
AVL树是严格的高度平衡，因此每当删除、插入一个节点的时候，最坏情况需要做 logn 次旋转的操作。红黑树可以通过调整颜色来处理，所以大大减少了旋转的次数。
哈希表的查找速度要优于红黑树，但是红黑树需要的内存小于哈希表，并且数据量很大时，哈希表会产生冲突。

# B-树
一个 m 阶的B树具有如下几个特征：
- 根节点至少有两个子女
- 每个中间节点都包含 k-1 个元素和 k 个孩子 m/2 ≤ k ≤ m
- 每个叶子节点都包含 k-1 个元素 m/2 ≤ k ≤ m
- 所有的叶子节点都位于同一层
- 每个节点的元素从小到大排列，节点当中 k-1 个元素正好是 k 个孩子的值域划分
![[Pasted image 20221219202408.png]]
当单一节点中的元素较多的时候，查询效率将飞速提升。在节点内部进行元素比较仅仅是多了几次内存交互，只要不超过磁盘页的大小即可。

[Introduction of B-Tree - GeeksforGeeks](https://www.geeksforgeeks.org/introduction-of-b-tree-2/)

# B+树
B+树是B树的一种变体，有着比B+树更高的查询性能。特征如下：
- 有 k 个子树的中间节点包含 k 个元素（B树是 k-1 个元素），每个元素保存的仅仅是索引
- 所有的叶子节点中包含了全部的元素信息，及指向这些元素记录的指针，且叶子节点本身按照关键字的大小自小而大的顺序链接
![[Pasted image 20221219203253.png]]

由于B+树的节点没有数据，所以可以容纳 k 个值，这就意味着数据量相同的情况下，B+树的结构比B树 "矮胖"，需要更少的IO次数。B+树的查询必须查找到叶子节点，而B树的查询找到匹配元素就行，因此B+树的查询是稳定的。B+树的范围查找，只需要在叶子节点上按照链表查询就可以。

总之，B+树的优点是 IO 次数少，查询性能稳定，范围查询更方便。MySQL数据库的索引就采用了B+树。

[A Short Tutorial on B+ Tree - Sayef's Tech Blog](http://sayef.tech/post/b-plus-tree-tutorial/)

# 排序算法
![[Pasted image 20221219003637.png]]

# 堆排序
建堆的时间复杂度是 $O(n)$ 
$$
\begin{aligned}
s &= \frac{n}{4} \times 1 + \frac{n}{8} \times 2 + \frac{n}{16} \times 3 + \cdots \\ s &= n \times (\frac{1}{4} + \frac{2}{8} + \frac{3}{16} + \cdots) \\ 2 \times s &= n \times (\frac{1}{2} + \frac{2}{4} + \frac{3}{8} + \frac{4}{16} \cdots) \\ 2 \times s - s &= n \times (\frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \frac{1}{16} \cdots) \\ s &\approx n
\end{aligned}
$$
堆调整的时间复杂度是 $O(logn)$ 的，需要调整 $n$ 次，所以堆排序的时间复杂度是 $O(n\ logn)$ 
``` cpp
void down(int u) {
  int t = u;
  if (2 * u <= n && h[2 * u] < h[t]) t = 2 * u;
  if (2 * u + 1 <= n && h[2 * u + 1] < h[t]) t = 2 * u + 1;
  if (t != u) {
    swap(h[t], h[u]);
    down(t);
  }
}

void up(int u) {
  while (u / 2 && h[u] < h[u / 2]) {
    heap_swap(u, u / 2);
    u >>= 1;
  }
}

for (int i = 1; i <= n; ++i) cin >> h[i];

for (int i = n / 2; i > 0; --i) down(i);

for (int i = n; i > 0; --i) {
  cout << h[1] << " ";
  h[1] = h[n--];
  down(1);
}
```

# 如何实现稳定的快排
牺牲空间，开辟一个大小为 n 的额外数组，遍历原数组将小于 x 的数依次放入新数组中。

# Hash负载因子
一句话总结就是负载因子太小，虽然时间效率提升了，但是空间利用率降低了。

