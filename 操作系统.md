# 进程与线程
进程表示资源分配的基本单位，也是调度运行的基本单位。线程是 CPU 调度，或者说是程序执行的最小单位。当我们启动一个新的进程，系统为它分配独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，进程切换的时候需要保存上下文信息。因此这是一种非常昂贵的多任务工作方式。而运行在一个进程中的线程，它们之间共享大部分的数据，使用相同的地址空间。每个线程只占有栈、寄存器和程序计数器等资源。因此启动一个线程，切换一个线程远比进程操作要快，花费也小得多。

线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据。而进程间的通信需要以通信的方式进行。不过如何处理好同步和互斥是多线程程序的难点。

多进程的程序更加的健壮，多线程程序只要一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对其余的进程造成影响，因为每个进程都有独立的地址空间。

# 协程
进程和线程是操作系统通过调度算法，保存当前的上下文，然后从上次暂停的地方再开始计算，重新开始的地方不可预期，因为每次 CPU 计算的指令数量和 CPU 时间是相关的，开发者无法精确的控制。

协程是一种轻量级的用户态线程，是一种非抢占式的调度。一个线程作为一个容器里面放置多个协程，当一个协程发现自己执行不下去了，就通知调度器。调度器根据事先设计好的调度算法找到当前最需要 CPU 的协程。切换这个协程的 CPU 上下文把 CPU 的运行权交个这个协程，直到这个协程出现执行不下去需要等等的情况，或者调用主动让出 CPU 的 API 之类，触发下一次调度。

**优点：**
- 协程在用户态，每个协程的体积比线程要小得多，因此一个进程可以容纳数量相当可观的协程
- 协作式的用户态调度器，减少了 CPU 上下文切换的开销，提高了 CPU 缓存命中率
- 减少同步加锁，整体上提高了性能
- 可以按照同步思维写异步代码，即用同步的逻辑，写由协程调度的回调

**缺点：**
- 在协程执行中不能有阻塞操作，否则整个线程被阻塞
- 需要特别关注全局变量的使用
- 协程可以处理 IO 密集型程序的效率问题，但是处理 CPU 密集型不是它的长处

# 线程共享哪些资源
线程占有的资源：栈、寄存器、状态/程序计数器
进程占有的资源：地址空间、全局变量、打开的文件、子进程、信号量、账户信息

# 进程间通信方式
每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程A把数据从用户空间拷到内核缓冲区，进程B再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信。

1. 匿名管道：一种半双工的通信方式，数据只能单向流动，而且只能在父子进程中使用。
2. 命名管道：以文件的形式存在于文件系统中。因此，只要可以访问文件，就可以通信。
3. 信号：Linux系统中用于进程间互相通信的一种机制，可以在任何时候发给某一进程。
4. 消息队列：存放在内核中的消息链表。由于消息队列存放在内核中，所以访问速度快。
5. 共享内存：使得多个进程可以直接读写同一块内存空间。最快的通信方式。
6. 信号量：信号量是一个计数器，用于多进程对共享数据的访问，用于进程间同步。
7. 套接字：通过IP地址和端口号形成一个标识，即可以在本地单机上进行通信，也可以跨网络。

# 最快的通信方式是什么
共享内存。因为进程可以直接读写内存，并不需要通过系统调用或者其它需要切入内核的过程来完成。同时它也避免了对数据的各种不必要的复制。需要考虑线程安全。对于管道和消息队列，则需要在内核和用户空间进行四次的数据拷贝（读写各两次)。消息队列每次读/写操作都是单个消息，保证每个操作都将成功处理整个消息，或者在不更改队列的情况下失败。所以消息的读取要么成功，要么就失败。数据不会丢失。

# 调用read操作发生了什么
程序调用 read 产生一次用户态到内核态的上下文切换，并且将磁盘中的文件内容拷贝到 OS 的文件系统缓冲区。然后将 OS 缓冲区的数据拷贝到用户缓冲区。系统调用 read 返回，这会导致从内核空间到用户空间的上下文切换。除此之外，Linux 还提供了 `mmap()` 系统调用，它可以将文件映射到进程的地址空间，这样程序就可以通过访问内存的方式去访问文件了，减少一次拷贝的操作。

# mmap的原理
mmap是一种内存映射文件的方法，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。

# IO流程
传统的 IO 流程，包括 read 和 write 的过程，流程图如下：
![[Pasted image 20230105224343.png]]
- 用户应用进程调用 read 函数，向操作系统发起 IO 调用， **上下文从用户态转为内核态（切换1）**
- DMA 控制器把数据从磁盘中，读取到内核缓冲区
- CPU 把内核缓冲区数据，拷贝到用户应用缓冲区， **上下文从内核态转为用户态（切换2）**
- 用户应用进程通过 write 函数，发起 IO 调用，**上下文从用户态转为内核态（切换3）**
- CPU 将用户缓冲区中的数据，拷贝到 socket 缓冲区
- DMA 控制器把数据从 socket 缓冲区，拷贝到网卡设备， **上下文从内核态切换回用户态（切换4）**

从流程图可以看出，**传统IO的读写流程**，包括了4次上下文切换，4次数据拷贝（读写各两次）

# 零拷贝
所谓零拷贝就是指的计算机执行 IO 操作时，CPU 不需要将数据从一个存储区域复制到另一个存储区域，从而可以减少上下文切换以及 CPU 的拷贝时间。零拷贝并不是没有拷贝数据，而是减少用户态/内核态的切换次数以及 CPU 拷贝的次数。零拷贝实现有多种方式，分别是：
- mmap + write
- sendfile
- 带有 DMA 收集拷贝功能的 sendfile

[看一遍就理解：零拷贝详解 | HeapDump性能社区](https://heapdump.cn/article/3290793)

# 线程间同步方式
同一进程的线程共享地址空间，没有通信的必要，但要做好同步/互斥，保护共享的全局变量。

<span class="red">互斥量(mutex)</span>是最基本的线程同步方式，它只有加锁和解锁两种状态。尝试对互斥量加锁的线程如果发现互斥量已经被其他线程上锁了，那该线程就会由运行态<span class="yellow">进入阻塞态</span>，即让出CPU，CPU可以调度其他线程运行，直到它想要的互斥量被其他线程释放了，CPU就可以把该线程转入就绪态准备调度其运行。

<span class="red">自旋锁(spinlock)</span>与互斥量的区别在于，它<span class="yellow">不会阻塞线程</span>。即尝试对自旋锁加锁的线程如果发现自旋锁已经被其他线程上锁了，那该线程将不会让出CPU，会一直处于运行态继续尝试获取该自旋锁，直到它的时间片耗尽让出CPU或者得到锁继续向下执行。

<span class="red">读写锁</span>适用于多读少写的情况，相比于互斥量，它把加锁态细分为读模式加锁和写模式加锁两种，从而允许更高程度的并行，允许多个读者同时访问共享资源，但写者将独占共享资源，所以读写锁也叫共享-互斥锁，即读模式共享，写模式互斥。

<span class="red">信号量</span>相当于对互斥量做了扩展，如果一个信号量只有值0和1，那它和互斥量的作用一样，1表示解锁的状态，0表示加锁的状态。多值信号量允许多个线程同时访问共享资源，并且信号量允许A线程加锁（减1），B线程解锁（增1），而对于互斥量则谁锁上的谁负责解开。

<span class="red">屏障</span>是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有的合作线程都到达某一点，然后从该点继续执行。

# 进程的状态
进程有三种状态，分别是阻塞、就绪和执行。它们之间存在转换关系，不存在阻塞⇒等待的转换。
![[Pasted image 20230105231058.png]]

# 进程切换会发生什么
Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好 CPU 寄存器（CPU 内置的容量小、但速度极快的内存）；程序计数器（存储 CPU 正在执行的指令位置、或者即将执行的下一条指令的位置）。

# Linux进程调度算法
1. 先来先服务：非抢占式，效率不高，有利于长作业（CPU繁忙型）而不利于短作业（IO繁忙型）。
2. 短作业优先：非抢占式，优先考虑短作业，具有很好的性能，降低平均等待时间，提高吞吐量。但是会造成长作业一直处于等待状态的情况，出现饥饿现象。
3. 最短剩余时间：优先考虑剩余时间最短的作业，是抢占式的，适合实时系统。
4. 时间片轮转：按照到达顺序，每个进程执行一个时间片的时间。
5. 高响应比优先：（等待时间 + 服务时间）/ 服务时间。

# 进程的地址空间
在 32 位模式下，每个进程能寻址的地址空间为 4G，最高的 1G 空间供内核使用，称为内核空间；剩余的 3G空间供各个进程使用。内核空间中存放的是内核代码和数据，用户空间中存放的是用户程序的代码和数据。

# 孤儿进程
父进程退出，子进程将成为孤儿进程，孤儿进程将被 init 进程收养，由 init 进程对它们完成状态收集工作。

# 僵尸进程
Unix 提供了一种机制可以保证父进程只要想知道子进程结束时的状态信息，就可以得到。每个进程退出的时候，内核释放资源，但是保留一定的信息：(进程号，退出状态，运行时间)，直到父进程通过 wait 或 waitpid 获取之后，才被释放。而父进程没有获取子进程的状态信息的话，子进程的进程描述符仍然保存在系统中，这种进程称为僵尸进程。

>僵尸进程具有很大的危害性，因为进程号一直不被释放，而且系统的进程号有限，如果存在大量的僵尸进程，将会导致系统不能产生新的进程。

追溯源头，只要把产生大量僵尸进程的父进程杀死，所有的僵尸进程变为孤儿进程由 init 接管，完成释放。

# 惊群效应
是指多进程（多线程）同时阻塞等待同一个事件的时候，如果等待的这个事件发生，那么他就会唤醒等待的所有进程（线程），但是最终只能有一个进程（线程）获得这个事件的控制权，对该事件进行处理，而其他进程则重新进入休眠状态，这种现象和性能浪费称为惊群效应。

# 惊群效应消耗了什么
系统对用户进程/线程频繁地做无效的调度，上下文切换系统性能大打折扣。为了确保只有一个线程得到资源，用户必须对资源操作进行加锁保护，进一步加大了系统开销。

# 如何解决惊群效应
Linux 2.6 版本之后，通过引入一个标记位，只会唤醒等待队列上的第一个线程。
Linux 4.5 解决了这一问题，使用 `EPOLLEXCLUSIVE` 标记。

# 什么是死锁
当线程 A 持有独占锁 a，并尝试去获取独占锁 b 的同时，线程 B 持有独占锁 b，并尝试获取独占锁 a 的情况下,就会发生 AB 两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。

死锁的四个必要条件：
- 互斥条件：资源每次只能被一个进程使用
- 请求保持条件：一个进程因为请求资源而被阻塞，不会释放自己的资源
- 不剥夺条件
- 循环等待条件

# 什么是虚拟内存
每个程序被运行起来后，都将拥有自己的独立**虚拟地址空间**，虚拟地址空间的大小由CPU的位数决定的，32位的机器的虚拟地址空间为4GB大小。一般来说，C语言指针大小的位数与虚拟空间的位数相同，如32位平台下的指针为32位， 即4字节。64位平台下的指针为64位，即8字节。

虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

操作系统为进程虚拟地址空间的每个区域分配了虚拟页：
- 代码和数据的虚拟页被分配到了适当位置，此时虚拟页状态为未缓冲，虚拟页指向了磁盘地址。
- 操作系统和共享库的虚拟页被映射到了物理内存，因为他们已经在内存了，这些虚拟页的状态为已缓冲。
- 用户栈，运行时堆的虚拟页没有任何分配，不占用任何空间，这些虚拟页的状态为未分配。

虚拟地址由虚拟页号+虚拟页偏移量组成，虚拟页偏移量是相对某个虚拟页的偏移量。页表是建立虚拟页号和物理页号映射关系的表结构，每个页表项包括了有效位，物理页号，磁盘地址等信息。

每个进程都有自己的页表，CPU执行某个进程时，会先把该进程的一级页表起始地址存储到页表基址寄存器，这样CPU查找一级页表起始地址可以直接从寄存器查找，加快了查找效率。

页表项命中的步骤：
1. CPU将虚拟地址送入MMU通过页表基址加上虚拟页号，计算出页表项在内存中的位置并读取。
2. 如果该页表项已缓冲，那么MMU就可以通过物理页号加上虚拟页偏移量形成物理地址
3. 根据计算的地址去内存中取出数据，返回给CPU

页表项未命中的步骤：
1. CPU将虚拟地址送入MMU通过页表基址加上虚拟页号，计算出页表项在内存中的位置并读取。
2. 发现页不在内存中，未命中，因此MMU发送一个缺页中断，交由缺页异常处理程序处理。
3. 缺页异常处理程序根据页置换算法，选择出一个牺牲页，如果这个页面已经被修改了，则写出到磁盘上，最后将这个牺牲页的页表项有效位设置为0。
4. 缺页异常程序处理程序调入新的页面，并将有效位为1，更新物理页号。
5. 回到发生缺页中断的指令处，执行命中的流程。

现代的CPU和操作系统为了加快虚拟地址翻译物理地址的过程，做了以下两点优化：
- 建立了虚拟页号与页表项的映射关系，存储在快表(TLB)中
- 某些热点内存对应的数据，存储在L1缓冲中

[彻底搞懂虚拟内存，虚拟地址，虚拟地址空间](https://www.eet-china.com/mp/a48477.html)

# 虚拟内存的好处
扩大地址空间：如果一个程序需要 6G 的内存，但是计算机实际的内存只有 4G，将会导致程序崩溃。
减少内存碎片：两个非连续的程序同时释放内存，此时两段内存相当于两个碎片，无法一起使用。
保护程序运行：许多程序是同时执行的，如果不使用虚拟内存来保证每个程序拥有独立的地址空间，那么不止一个程序可以访问同一地址的内存，将会出现脏数据。

[Why Do We Need Virtual Memory? | Baeldung on Computer Science](https://www.baeldung.com/cs/virtual-memory-why)

# 缺页中断
在请求分页系统中，可以通过查询页表的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不再内存中，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。通常的中断处理需要经历四个处理步骤：保护CPU现场；分析中断原因；转入中断处理程序进行处理；恢复CPU现场，继续执行。

# 页面置换算法
最佳置换算法(OPT)；先进先出(FIFO)；最近最近未使用(LRU)；最近最少使用(LFU)；时钟置换

# Cache
## Cache的原理
CPU速度快于内存读写速度100多倍，Cache为了避免内存成为CPU速度的瓶颈。大部分的程序，在处理数据时，都有一定程度的区域性。所以，我们可以用一小块快速的内存，来暂存目前需要的数据。

>局部性原理：当一个指令或数据被访问过之后，与它相邻地址的数据有很大概率也会被访问，将更多可能被访问的数据存入缓存，可以提高缓存命中率。

## Cache三级缓存
现代的CPU已经普遍采用 L1/L2/L3 多级缓存的结构来改善性能。自顶向下容量逐渐增大，访问速度也逐渐降低，当缓存未命中时，缓存系统会向更底层的层次搜索。
-   **L1 Cache：** 在 CPU 核心内部，分为指令缓存和数据缓存，分开存放 CPU 使用的指令和数据；
-   **L2 Cache：** 在 CPU 核心内部，尺寸比 L1 更大；
-   **L3 Cache：** 在 CPU 核心外部，所有 CPU 核心共享同一个 L3 缓存。

以一台8核CPU的电脑为例，每个Cache的大小为：
- L1 Cache：512KB  =（32KB数据缓存 + 32KB指令缓存）* 8核
- L2 Cache：2MB = 256KB * 8核
- L3 Cache：12MB 

## L1为什么分指令和数据存储
主要原因是避免**指令单元**和**数据单元**同时竞争一个缓存单元，降低 CPU 运行效率；另外因为在内存中指令和数据并不是随机分布的，而是相对聚集地分开存储的。所以分开存储策略更符合内存数据的现状。

## L2为什么不分离存储
1）L1采用分离缓存后已经解决了指令单元和数据单元的争夺访缓存问题，所以L2是否使用分离缓存没有影响。
2）当缓存容量较大时，不能最大化发挥缓存容量的利用率。例如数据缓存满了，但是指令缓存还有空闲，而 L2 使用统一缓存则能够保证最大化利用缓存空间。

## 内存与Cache的映射
目前，主要有 3 种映射方案：1）直接映射；2）全相联映射；3）组相联映射。

直接映射是三种方式中最简单的映射方式，直接映射的策略是： 在内存块和缓存块之间建立起固定的映射关系，一个内存块总是映射到同一个缓存块上。就如每个人的停车位是固定分配好的，可以直接找到。
直接映射存在以下两个问题：
1. **缓存利用不充分：** 每个内存块只能映射到固定的位置上，即使 Cache 上有空闲位置也不会使用；
2. **块冲突率高：** 直接映射会频繁出现块冲突，导致<span class="red">Cache淘汰换出频繁</span>，需要频繁的从主存读取数据到Cache，这个代价也较高。

全相联映射的策略是： 允许内存块映射到任何一个Cache块上。 这种方式能够充分利用Cache的空间，块冲突率也更低，只要淘汰Cache中的某一块，即可调入主存的任一块。但是，由于Cache比较电路的设计和实现比较困难，这种方式只适合于**小容量**Cache采用。

组相联映射是直接映射和全相联映射的折中方案，组相联映射的策略是： 将Cache分为多组，每个内存块固定映射到一个分组中，又允许映射到组内的任意Cache块。显然，组相联的分组为1时就等于全相联映射，而分组等于Cache块个数时就等于直接映射。

## Cache替换策略
1）**随机法：** 使用一个随机数生成器随机地选择要被替换的 Cache 块，实现简单，缺点是没有利用 “局部性原理”，无法提高缓存命中率；
2）**FIFO 先进先出法：** 记录各个 Cache 块的加载事件，最早调入的块最先被替换，缺点同样是没有利用 “局部性原理”，无法提高缓存命中率；
3）**LRU 最近最少使用法：** 记录各个 Cache 块的使用情况，最近最少使用的块最先被替换。这种方法相对比较复杂，也有类似的简化方法，即记录各个块最近一次使用时间，最久未访问的最先被替换。与前 2 种策略相比，LRU 策略利用了 “局部性原理”，平均缓存命中率更高。
[CPU三级缓存的秘密](https://www.cnblogs.com/pengxurui/p/16898159.html)
[主存到Cache直接映射、全相联映射和组相联映射](https://blog.csdn.net/dongyanxia1000/article/details/53392315)
[深入理解Cache工作原理 - 小林野夫 - 博客园](https://www.cnblogs.com/cdaniu/p/15601051.html)

# select
select，poll，epoll 都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。它们本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。
``` cpp
#include <sys/select.h>

// 成功返回大于0的整数，这个整数表示就绪描述符的数目。
int select(int n,
           fd_set *readfds, fd_set *writefds, fd_set *exceptfds,
           struct timeval *timeout);

int FD_ZERO(int fd, fd_set *fdset);   // 所有位都设为 0
int FD_CLR(int fd, fd_set *fdset);    // 清除某个位时可以使用
int FD_SET(int fd, fd_set *fd_set);   // 设置变量的某个位置
int FD_ISSET(int fd, fd_set *fdset);  // 测试某个位是否被置
```
`fd_set` 是一个 int 型数组，大小为 32，每一位都对应一个文件描述符，所以 32 * 32 = 1024 。select 函数监视的文件描述符分 3 类：writefds、readfds、和 exceptfds ，调用后 select 函数会阻塞，直到有描述符就绪，或者超时函数返回。

**优点：**
- select 的可移植性更好，在某些 Unix 系统上不支持 poll
- select 对于超时值提供了更好的精度(微秒)，而 poll 是毫秒
**缺点：**
- 单个进程可监视的 fd 数量被限制
- 每次都需要重新将监控集合拷贝到内核
- 每次返回都会修改监控集合，因此每次都需要用户重新向集合中添加描述符
- 用户遍历描述符是否在集合中来判断哪个描述符就绪，这个判断是一个遍历的过程，性能随着描述符增多而下降，并且复杂度更高

# poll
每一个 `pollfd` 结构体指定了一个被监视的文件描述符；每个结构体的 `events` 是监视该文件描述符的事件掩码，由用户来设置这个域； `revents` 是文件描述符的操作结果事件掩码，内核在调用返回时设置这个域。
``` cpp
struct pollfd {
  int fd;        /* file descriptor */
  short events;  /* requested events to watch */
  short revents; /* returned events witnessed */
};

int poll(struct pollfd *fds, unsigned int nfds, int timeout);
```

**优点：**
- poll 没有描述符上限的设置
- poll 采用事件结构形式对描述符关心的事件进行监控，简化了select三种集合的操作流程
**缺点：**
- 同样每次都需要将监控集合拷贝到内核
- 在内核中进行轮询遍历判断就绪，性能随着描述符事件增多而下降
- 不会告诉用户哪一个描述符就绪，需要用户轮询遍历判断事件中的 `revents`

# epoll
epoll 使用一个文件描述符管理多个描述符，将用户关心的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的只需 copy 一次。
``` cpp
// 创建一个epoll，参数size用来告诉内核监听的文件描述符的个数，跟内存大小有关。
int epoll_create(int size);

// 将文件描述符fd交给epoll的fd进行管理
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);

// 等待所监控文件描述符上有事件的产生, events用来从内核得到就绪事件的集合
int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);
```

调用 `epoll_create` 时，内核除了帮我们在 epoll 文件系统里建了个 file 结点，在内核 cache 里建了个红黑树用于存储以后 epoll_ctl 传来的 socket 外，还会再建立一个 list 链表，用于存储准备就绪的事件，当 epoll_wait 调用时，仅仅观察这个 list 链表里有没有数据即可。有数据就返回，没有数据就 sleep，等到 timeout 时间到后即使链表没数据也返回

**缺点：**
- 改变监听事件的类型（例如从读事件改为写事件）需要调用 `epoll_ctl` 系统调用。
- 每一个被 accept 的套接字都需要添加到集合中，在 epoll 中必须使用 `epoll_ctl` 来添加，这就意味着每一个新的连接都需要两次系统调用，而在 poll 中只需要一次。如果你的服务有非常多的短连接它们都接受或者发送少量数据，epoll 所花费的时间可能比 poll 更长。
- 同一时刻你的应用程序监听的套接字少于 1000（这种情况下使用epoll不会得到任何益处）

# Epoll的两种工作方式
**水平触发（LT）**：是缺省的工作方式，并且同时支持 block 和 non-block socket。在这种做法中，只要内核缓冲区中还有未读数据，就会一直返回描述符的就绪状态，然后你可以对这个就绪的 fd 进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。
``` cpp
// 当listenfd就绪后，我们只需要调用accept一次，然后epoll_wait等待下次通知
connfd = accept(listenfd , (struct sockaddr *)&cliaddr, &clilen);

// 读取数据
ret = read(fd, buf, sizeof(buf));
```

**边沿触发（ET）**：是高速工作方式，只支持 no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过 epoll 告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，等到下次有新的数据进来的时候才会再次出发就绪事件。
``` cpp
while (true) {
  connfd = accept(listenfd, (struct sockaddr *)&cliaddr, &clilen);
  if (connfd < 0) break;
}

while (true) {
  ret = read(fd, buf, sizeof(buf);
  if (ret == EAGAIN) break;
}
```

ET 模式在很大程度上减少了事件被重复触发的次数，因此效率要比 LT 模式高。epoll 工作在 ET 模式的时候，必须使用非阻塞IO，因为阻塞式IO会在读完之后一直阻塞下去，非阻塞IO则会返回 < 0，并返回 EAGAIN 。

# fork 和 vfork 的区别
早期的 fork 并没有实现写时复制，所以 fork 后的子进程不但会拷贝父进程的页表项，还会按页复制父进程地址空间中的内容。但是如果子程序调用 exec 来加载新的二进制文件，复制父进程就成了无用功。所以就诞生了vfork，子进程与父进程共享共享数据段。另外，vfork 保证了子程序先执行，在它调用 exec 或者 exit 之后父进程才能被调度运行。

# 单核机器上多线程程序，需要加锁么
在单核机器上仍然存在同步的问题，因为在抢占式系统中，通常为每个线程分配一个时间片，如果两个线程共享一个数据，开始时线程A对数据进行操作，中途被线程B抢占。如果不加锁，B就会修改共享的数据。加了锁，B就会被阻塞。

# CPU占用100%如何排查
`top` 命令后，输入 P，查看占用 100% 的进程id
`top -Hp pid` 得到线程号
`pstack 进程号`，查看相应的堆栈信息

# Linux内存分布与管理方式
Linux 操作系统采用虚拟内存管理技术，使得每个进程都有各自互不干涉的进程地址空间。该空间是块大小为4G的线性虚拟空间，用户接触到的都是该虚拟地址，无法看到实际的物理内存地址。

**1. 物理内存管理**
Linux 内核管理物理内存是通过分页机制实现的，它将整个内存划分成无数个4k大小的页面。使用伙伴系统算法来解决外部碎片的问题。把所有的空闲页框分组为 11 块链表，每一块链表分别包含大小为1，2，4，8，16，32，64，128，256，512，1024 个连续的页框。

假设要请求一个256（129~256）个页框的块。算法先在256个页框的链表中检查是否有一个空闲块。如果没有这样的块，算法会查找下一个更大的页块，也就是，在512个页框的链表中找一个空闲块。如果存在这样的块，内核就把512的页框分成两等分，一般用作满足需求，另一半则插入到256个页框的链表中。如果在512个页框的块链表中也没找到空闲块，就继续找更大的块——1024个页框的块。如果这样的块存在，内核就把1024个页框块的256个页框用作请求，然后剩余的768个页框中拿512个插入到512个页框的链表中，再把最后的256个插入到256个页框的链表中。如果1024个页框的链表还是空的，算法就放弃并发出错误信号。

**2. 内核内存管理**
以页为最小单位分配内存对于内核管理系统中的物理内存来说的确比较方便，但内核自身最常使用的内存却往往是很小（远远小于一页）的内存块。

slab 分配器是基于对象进行管理的，相同类型的对象归为一类（如进程描述符是一类），每次当要申请这样一个对象，slab 分配器就从一个 slab 列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存到该列表中，而不是直接返回给伙伴系统，从而避免这些内存碎片。
